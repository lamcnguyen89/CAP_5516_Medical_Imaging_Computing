{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from segment_anything import sam_model_registry\n",
    "\n",
    "def train_lora_sam(config):\n",
    "    # Initialize SAM with LoRA\n",
    "    sam = sam_model_registry[config[\"model_type\"]](checkpoint=config[\"checkpoint\"])\n",
    "    sam = add_lora_to_sam(sam, rank=config[\"rank\"])\n",
    "    sam.to(config[\"device\"])\n",
    "    \n",
    "    # Only optimize LoRA parameters\n",
    "    optimizer = optim.Adam(\n",
    "        [p for p in sam.parameters() if p.requires_grad],\n",
    "        lr=config[\"lr\"],\n",
    "        weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "    \n",
    "    # Loss function - adjust based on your task\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        sam.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # Training phase\n",
    "        for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            images, masks = images.to(config[\"device\"]), masks.to(config[\"device\"])\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = sam(images, multimask_output=False)\n",
    "            loss = criterion(outputs['masks'], masks)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        sam.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(config[\"device\"]), masks.to(config[\"device\"])\n",
    "                outputs = sam(images, multimask_output=False)\n",
    "                loss = criterion(outputs['masks'], masks)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        # Print statistics\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': sam.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "            }, config[\"save_path\"])\n",
    "    \n",
    "    return sam\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    \"model_type\": \"vit_b\",  # or \"vit_l\", \"vit_h\" depending on your SAM version\n",
    "    \"checkpoint\": \"sam_vit_b_01ec64.pth\",\n",
    "    \"rank\": 8,\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"epochs\": 20,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"save_path\": \"best_lora_sam.pth\"\n",
    "}\n",
    "\n",
    "# Start training\n",
    "trained_sam = train_lora_sam(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "def predict_with_lora_sam(model, image, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Preprocess your image (resize, normalize, etc.)\n",
    "        image_tensor = preprocess_image(image).to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = model(image_tensor, multimask_output=False)\n",
    "        \n",
    "        # Post-process masks\n",
    "        masks = torch.sigmoid(outputs['masks'])\n",
    "        masks = (masks > 0.5).float()\n",
    "        \n",
    "    return masks.cpu().numpy()\n",
    "\n",
    "# Load saved model\n",
    "checkpoint = torch.load(\"best_lora_sam.pth\")\n",
    "sam.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Example prediction\n",
    "test_image = load_your_test_image()\n",
    "predicted_mask = predict_with_lora_sam(sam, test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "\n",
    "def calculate_iou(preds, targets):\n",
    "    intersection = (preds & targets).float().sum()\n",
    "    union = (preds | targets).float().sum()\n",
    "    return (intersection + 1e-6) / (union + 1e-6)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_iou = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images, multimask_output=False)\n",
    "            preds = (torch.sigmoid(outputs['masks']) > 0.5).float()\n",
    "            total_iou += calculate_iou(preds, masks)\n",
    "    return total_iou / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "def prepare_kfold_data(image_paths, mask_paths, n_splits=5):\n",
    "    \"\"\"Prepare KFold splits while maintaining image-mask pairs\"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    folds = []\n",
    "    \n",
    "    # Create indices array (assuming image_paths and mask_paths are aligned)\n",
    "    indices = np.arange(len(image_paths))\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(indices):\n",
    "        folds.append({\n",
    "            'train': (np.array(image_paths)[train_idx].tolist(), \n",
    "                     np.array(mask_paths)[train_idx].tolist()),\n",
    "            'val': (np.array(image_paths)[val_idx].tolist(),\n",
    "                   np.array(mask_paths)[val_idx].tolist())\n",
    "        })\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Training Loop\n",
    "\n",
    "from copy import deepcopy\n",
    "from segment_anything import sam_model_registry\n",
    "\n",
    "def cross_validate_sam_lora(config, image_paths, mask_paths):\n",
    "    # Prepare 5 folds\n",
    "    folds = prepare_kfold_data(image_paths, mask_paths)\n",
    "    fold_results = []\n",
    "    best_models = []\n",
    "    \n",
    "    for fold_idx, fold in enumerate(folds):\n",
    "        print(f\"\\n=== Processing Fold {fold_idx + 1}/5 ===\")\n",
    "        \n",
    "        # Initialize fresh model for each fold\n",
    "        sam = sam_model_registry[config[\"model_type\"]](checkpoint=config[\"checkpoint\"])\n",
    "        sam = add_lora_to_sam(sam, rank=config[\"rank\"])\n",
    "        sam.to(config[\"device\"])\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = SAMDataset(fold['train'][0], fold['train'][1])\n",
    "        val_dataset = SAMDataset(fold['val'][0], fold['val'][1])\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"])\n",
    "        \n",
    "        # Train the model\n",
    "        model, fold_metrics = train_single_fold(\n",
    "            sam=sam,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            config=config,\n",
    "            fold_idx=fold_idx\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        fold_results.append(fold_metrics)\n",
    "        best_models.append(deepcopy(model.state_dict()))\n",
    "        \n",
    "        # Clean up\n",
    "        del sam\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return fold_results, best_models\n",
    "\n",
    "def train_single_fold(sam, train_loader, val_loader, config, fold_idx):\n",
    "    optimizer = optim.Adam(\n",
    "        [p for p in sam.parameters() if p.requires_grad],\n",
    "        lr=config[\"lr\"],\n",
    "        weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "    best_val_loss = float('inf')\n",
    "    fold_metrics = {'train_loss': [], 'val_loss': [], 'val_iou': []}\n",
    "    \n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        # Training phase\n",
    "        sam.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(config[\"device\"]), masks.to(config[\"device\"])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = sam(images, multimask_output=False)\n",
    "            loss = criterion(outputs['masks'], masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_iou = evaluate_fold(sam, val_loader, config[\"device\"])\n",
    "        \n",
    "        # Update metrics\n",
    "        epoch_train_loss /= len(train_loader)\n",
    "        fold_metrics['train_loss'].append(epoch_train_loss)\n",
    "        fold_metrics['val_loss'].append(val_loss)\n",
    "        fold_metrics['val_iou'].append(val_iou)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"Fold {fold_idx+1} | Epoch {epoch+1}: \"\n",
    "              f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, \"\n",
    "              f\"Val IoU: {val_iou:.4f}\")\n",
    "        \n",
    "        # Save best model for this fold\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = deepcopy(sam.state_dict())\n",
    "    \n",
    "    return sam, fold_metrics\n",
    "\n",
    "def evaluate_fold(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images, multimask_output=False)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs['masks'], masks)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate IoU\n",
    "            preds = (torch.sigmoid(outputs['masks']) > 0.5).float()\n",
    "            batch_iou = calculate_iou(preds, masks)\n",
    "            total_iou += batch_iou\n",
    "    \n",
    "    return total_loss / len(dataloader), total_iou / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Cross Validation\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    \"model_type\": \"vit_b\",\n",
    "    \"checkpoint\": \"sam_vit_b_01ec64.pth\",\n",
    "    \"rank\": 8,\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 4,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "# Example image and mask paths (replace with your actual paths)\n",
    "image_paths = [\"image1.npy\", \"image2.npy\", ...]  \n",
    "mask_paths = [\"mask1.npy\", \"mask2.npy\", ...]\n",
    "\n",
    "# Run cross-validation\n",
    "fold_results, best_models = cross_validate_sam_lora(config, image_paths, mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing Results\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_cv_results(fold_results):\n",
    "    # Convert to DataFrame for analysis\n",
    "    metrics = []\n",
    "    for i, fold in enumerate(fold_results):\n",
    "        best_epoch = np.argmin(fold['val_loss'])\n",
    "        metrics.append({\n",
    "            'fold': i+1,\n",
    "            'best_train_loss': fold['train_loss'][best_epoch],\n",
    "            'best_val_loss': fold['val_loss'][best_epoch],\n",
    "            'best_val_iou': fold['val_iou'][best_epoch],\n",
    "            'final_val_iou': fold['val_iou'][-1]\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(metrics)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n=== Cross-Validation Results ===\")\n",
    "    print(df)\n",
    "    print(\"\\nMean Validation IoU:\", df['best_val_iou'].mean())\n",
    "    print(\"Std Dev Validation IoU:\", df['best_val_iou'].std())\n",
    "    \n",
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i, fold in enumerate(fold_results):\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(fold['train_loss'], label=f'Fold {i+1}')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(fold['val_iou'], label=f'Fold {i+1}')\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Validation IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "results_df = analyze_cv_results(fold_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Selection\n",
    "\n",
    "# Option 1: Select best fold model\n",
    "best_fold_idx = np.argmax([res['val_iou'][-1] for res in fold_results])\n",
    "best_model_state = best_models[best_fold_idx]\n",
    "\n",
    "# Option 2: Create ensemble of all folds\n",
    "class EnsembleSAM(nn.Module):\n",
    "    def __init__(self, model_states, config):\n",
    "        super().__init__()\n",
    "        self.models = []\n",
    "        for state in model_states:\n",
    "            model = sam_model_registry[config[\"model_type\"]](checkpoint=None)\n",
    "            model.load_state_dict(state)\n",
    "            self.models.append(model.to(config[\"device\"]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for model in self.models:\n",
    "            outputs.append(model(x, multimask_output=False)['masks'])\n",
    "        return torch.mean(torch.stack(outputs), dim=0)\n",
    "\n",
    "# Initialize ensemble\n",
    "ensemble_model = EnsembleSAM(best_models, config)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
