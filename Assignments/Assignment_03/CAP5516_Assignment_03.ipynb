{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **CAP 5516 - Medical Image Computing (Spring 2025)**\n",
    "Programming Assignment #3 (40 points) \\\n",
    "**Due: 4/11/2025, 11:59 PM (EST)** \\\n",
    "\n",
    "\n",
    "## **Parameter Efficient Fine-tuning Foundation Model for Nuclei Instance Segmentation**\n",
    "\n",
    "### 1. **Dataset** \n",
    "\n",
    "NuInsSeg: A Fully Annotated Dataset for Nuclei Instance Segmentation in H&E-Stained Histological Images [1].\n",
    "The dataset and detailed step-by-step instructions to generate related segmentation masks are publicly available at\n",
    "https://www.kaggle.com/datasets/ipateam/nuinsseg and https://github.com/masih4/NuInsSeg, respectively.\\\n",
    "The dataset can also be downloaded from here: https://zenodo.org/records/10518968\n",
    "\n",
    "### 2. **Task**\n",
    "\n",
    "Review the dataset paper [1] and its corresponding GitHub repository [2] to familiarize yourself with the\n",
    "experimental setup. You will follow the experiment setting as described in the paper.\n",
    "For segmentation, we will utilize the Segment Anything Model (SAM) [3]. To enhance resource efficiency, select\n",
    "one of the optimized versions of the original SAM model: MobileSAM [4], EfficientSAM [5], or TinySAM [6]. You\n",
    "may choose any of these variants along with their pre-trained models. I highly suggest you use these efficient SAM\n",
    "models. However, if you have the resource to run the original SAM model, that is also fine.\n",
    "Assuming the use of the MobileSAM model, we will apply LoRA [7] for parameter-efficient fine-tuning to perform\n",
    "nuclei instance segmentation on the NuInsSeg dataset [1].\n",
    "\n",
    "### 3. **What to report**\n",
    "\n",
    "1) The details of your implementation of applying LoRA for efficient fine-tuning.\n",
    "2) Follow Table 3 in the dataset paper [1] and report the average results based on five-fold cross-validation in\n",
    "terms of those metrics (e.g., Dice, AJI, PQ). I hope your results can be much better than those baseline\n",
    "methods in the paper.\n",
    "3) Since we will use LoRA for fine tuning, report the # of tunable parameters.\n",
    "4) Provide a few examples of visual comparison of the predicted segmentation masks and the ground truth\n",
    "masks.\n",
    "\n",
    "### 4. **What to submit** ###\n",
    "\n",
    "(1) A report for this assignment. Specifically, a detailed network architecture framework (figure) is required. For\n",
    "example, how the LoRA layers are applied in your efficient fine-tuning framework. The implementation details are\n",
    "important.\\\n",
    "(2) Clean code and clear instructions (e.g., a readme file) to reproduce your results. If you choose to host the code on\n",
    "GitHub, please provide the GitHub link.\n",
    "\n",
    "\n",
    "**Useful resources (e.g. examples of applying LoRA for SAM fine tuning)**\n",
    "1. Finetune SAM on your customized medical imaging dataset https://github.com/mazurowski-lab/finetune-\n",
    "SAM\n",
    "2. Medical SAM Adapter https://github.com/SuperMedIntel/Medical-SAM-Adapter\n",
    "3. https://github.com/tianrun-chen/SAM-Adapter-PyTorch\n",
    "4. MeLo: Low-rank Adaptation is Better than Finetuning for Medical Image\n",
    "https://github.com/JamesQFreeman/LoRA-ViT\n",
    "5. SAMed: https://github.com/hitachinsk/SAMed\n",
    "6. How to build the best medical image segmentation algorithm using foundation models: a comprehensive\n",
    "empirical study with Segment Anything Model https://arxiv.org/pdf/2404.09957\n",
    "\n",
    "### **References**\n",
    "[1] Mahbod, Amirreza, Christine Polak, Katharina Feldmann, Rumsha Khan, Katharina Gelles, Georg Dorffner,\n",
    "Ramona Woitek, Sepideh Hatamikia, and Isabella Ellinger. \"NuInsSeg: A fully annotated dataset for nuclei instance\n",
    "segmentation in H&E-stained histological images.\" Scientific Data 11, no. 1 (2024): 295.\n",
    "https://arxiv.org/pdf/2308.01760\\\n",
    "[2] https://github.com/masih4/NuInsSeg?tab=readme-ov-file#codes-to-generate-segmentation-masks\\\n",
    "[3] Kirillov, Alexander, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao et al.\n",
    "\"Segment anything.\" In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 4015-\n",
    "4026. 2023.\\\n",
    "[4] Zhang, Chaoning, Dongshen Han, Yu Qiao, Jung Uk Kim, Sung-Ho Bae, Seungkyu Lee, and Choong Seon\n",
    "Hong. \"Faster segment anything: Towards lightweight sam for mobile applications.\" arXiv preprint\n",
    "arXiv:2306.14289 (2023). [Code] https://github.com/ChaoningZhang/MobileSAM\\\n",
    "[5] Xiong, Yunyang, Bala Varadarajan, Lemeng Wu, Xiaoyu Xiang, Fanyi Xiao, Chenchen Zhu, Xiaoliang Dai et\n",
    "al. \"Efficientsam: Leveraged masked image pretraining for efficient segment anything.\" In Proceedings of the\n",
    "IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 16111-16121. 2024. [Code]\n",
    "https://github.com/yformer/EfficientSAM (You can choose the smallest model EfficientSAM-Tiny)\\\n",
    "[6] Shu, Han, Wenshuo Li, Yehui Tang, Yiman Zhang, Yihao Chen, Houqiang Li, Yunhe Wang, and Xinghao Chen.\n",
    "\"Tinysam: Pushing the envelope for efficient segment anything model.\" arXiv preprint arXiv:2312.13789 (2023).\n",
    "[Code] https://github.com/xinghaochen/TinySAM\\\n",
    "[7] Hu, Edward J., Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\n",
    "Weizhu Chen. \"Lora: Low-rank adaptation of large language models.\" arXiv preprint arXiv:2106.09685 (2021).\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Prepare the SAM (Segment Anything Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use EfficientSAM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LORA for parameter efficient finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Nuclei Instance Segmentation on NulnSeg Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Using 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
